\documentclass[landscape]{foils} 
\input{../common-preamble-start}
\input{../preamble.tex}
\input{../common-preamble-end}
\usepackage{pdfpages}
\usepackage{bm}
\usepackage{ifsym}
\usepackage{mathrsfs}

\begin{document}
\pagecolor{white}
\unitlength=1mm
\begin{center}
{\Large Some of these slides have been borrowed from Dr.\ Paul Lewis, Dr.\ Joe Felsenstein. Thanks!}
\vskip 15mm
\large Paul has many great tools for teaching phylogenetics at his web site: \\
\url{http://hydrodictyon.eeb.uconn.edu/people/plewis}
\end{center}

\myNewSlide
\Large
Overview:
\begin{compactitem}
	\item Bootstrapping to estimate clade support
	\item controversies about the interpretation of the bootstrap support
	\item the AU test
\end{compactitem}

\myNewSlide
\includepdf[pages={33-34}]{../nonfreeimages/joe/joeTesting.pdf} 

\myNewSlide
\includepdf[pages={4-7}]{../nonfreeimages/pol/polBoot.pdf} 

\myNewSlide
Bootstrap support for branches can be displayed:
\begin{compactitem}
	\item on the best estimate of the tree (on the MP, OLS, or ML tree)
	\item on a majority-rule consensus tree \citep[see][]{BerryG1996}
\end{compactitem}


\myNewSlide
\large
Bootstrap proportions have been characterized as providing:
\begin{compactitem}
	\item a measure of repeatability,
	\item an estimate of the probability that the tree is correct (and bootstrapping has been criticized as being too conservative in this context),
	\item the P-value for a tree or clade
\end{compactitem}





\myNewSlide
\section*{Bootstrap Proportion $\neq$ Posterior Probability}
Several studies have compared the non-parametric bootstrap proportion of clade from an ML analysis of a data set to the posterior probabilities when the same data is analyzed under the same model \citep{SuzukiGN2002,WilcoxZHH2002,AlfaroZL2003,CummingsHMRRW2003,DouadyDBDD2003}.\par

{\em \bf Not} all of these have implied that the measures {\em\bf should} be the same, but some authors have, usually citing \citet{EfronHH1996}.

\myNewSlide
\section*{Bootstrap Proportion $\neq$ Posterior Probability in general}
\begin{picture}(-0,0)(-0,0)
	\put(40,30){\makebox(30,-150)[l]{\includegraphics[scale=2]{../images/WilcoxZHH-figure.pdf}}}
	\put(40,-130){from \citet{WilcoxZHH2002}}
\end{picture}


\myNewSlide
\section*{What did \citet{EfronHH1996} say?}
\normalsize
We can use a Bayesian model to show that $\tilde{\alpha}$ is a reasonable 
assessment of the probability that $\mathscr{R}_1$ contains $ \mu$.
Suppose we believe \textit{a priori} that $\mu$ could lie anywhere in the plane with 
equal probability. 
Then having observed $\hat{\mu}$, the \textit{a posteriori} 
distribution of  $\mu$ given  $\hat{\mu}$ is $N_2( \hat{\mu},I)$ exactly the same as the 
bootstrap distribution of $\hat{\mu}^{\ast}$. 
In other words, $\tilde{\alpha}$ is the  \textit{a posteriori}
probability of the event $\mu \in \mathscr{R}_1$, if we begin with an ``uninformative'' prior density for $\mu$.
\begin{picture}(-0,0)(-0,0)
	\put(0,20){\makebox(30,-150)[l]{\includegraphics[scale=4]{../images/EfronHH-straight-fig.pdf}}}
\end{picture}

\myNewSlide
\section*{\citet{EfronHH1996} view of tree space}
\begin{picture}(-0,0)(-0,0)
	\put(-10,10){\makebox(30,-150)[l]{\includegraphics[scale=3]{../images/EfronHH-treespace-fig.pdf}}}
\end{picture}

\myNewSlide
\section*{\citet{Kim2000} view of tree space}
\begin{picture}(-0,0)(-0,0)
	\put(-10,10){\makebox(30,-150)[l]{\includegraphics[scale=2.5]{../images/Kim-treespace.pdf}}}
\end{picture}

\myNewSlide
\section*{Parsimony-informative Pattern Frequency Space}
\begin{picture}(-0,0)(-0,0)
	\put(10,-20){\makebox(30,-150)[l]{\includegraphics[scale=1.]{../images/simple-treespace.pdf}}}
\end{picture}

\myNewSlide
\section*{Pattern Frequency Space With Observed Data}
\begin{picture}(-0,0)(-0,0)
	\put(10,-20){\makebox(30,-150)[l]{\includegraphics[scale=1.]{../images/simple-treespace-sample.pdf}}}
	\put(135,-83){$\hat{\mu}$}
\end{picture}

\myNewSlide
\section*{Bootstrapping in Pattern Frequency Space}
\begin{picture}(-0,0)(-0,0)
	\put(10,-20){\makebox(30,-150)[l]{\includegraphics[scale=1.]{../images/simple-treespace-boot.pdf}}}
\end{picture}

\myNewSlide
\section*{Posterior Densities in Pattern Frequency Space}
\begin{picture}(-0,0)(-0,0)
	\put(10,-20){\makebox(30,-150)[l]{\includegraphics[scale=1.]{../images/simple-treespace-pp1.pdf}}}
\end{picture}

\myNewSlide
\section*{Posterior Densities in Pattern Frequency Space}
\begin{picture}(-0,0)(-0,0)
	\put(10,-20){\makebox(30,-150)[l]{\includegraphics[scale=1.]{../images/simple-treespace-pp.pdf}}}
\end{picture}


\myNewSlide
\section*{What did \citet{EfronHH1996} say (and mean)?}
\begin{itemize}
	\item the ``uninformative'' prior density is a uniform prior over all of pattern space
	\item this is {\em not} equivalent to a prior that would be expected to yield a phylogeny (it is actually identical to the prior you would get if you assumed that all pairwise distances between taxa were $\infty$),
	\item  \citet{EfronHH1996}  were {\em not} predicting that the bootstrap proportions should be identical to those from a Bayesian phylogenetic analysis with real phylogenetic priors.
	\item  \cite{SvennbladEOB2006} have a nice paper on this subject.
\end{itemize}

\myNewSlide
\large
Bootstrap proportions have been characterized as providing:
\begin{compactitem}
	\item {\color{grey} a measure of repeatability,}
	\item  {\color{grey} an estimate of the probability that the tree is correct (and criticized as being too conservative in this context),}
	\item the P-value for a tree or clade
\end{compactitem}


\myNewSlide
\section*{coin flipping (yet again)}
$N=100$ and $H=60$

Can we reject the hypothesis of a fair coin?

We can use simulation to generate the null distribution (we could actually use the binomial distribution to analytically solve this one)...

\myNewSlide

\begin{picture}(0,0)(0,0)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.0]{../images/nullhist.pdf}}}
	\put(180,-60){\color{red} P-value $\approx$ 0.029 }
\end{picture}

\myNewSlide
If we bootstrap we get a sense of the variability in our estimate, but we can also get a tail probability for $\Pr(p^{(boot)} \leq 0.5)$

\myNewSlide

\begin{picture}(0,0)(0,0)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.0]{../images/boothist.pdf}}}
	\put(40,-60){\color{red}$ \Pr(p^{(boot)} \leq 0.5)\approx$ 0.027 }
\end{picture}

\myNewSlide
\begin{picture}(-0,0)(-0,0)
	\put(60,40){\makebox(30,-150)[l]{\includegraphics[scale=0.5]{../images/nullhist.pdf}}}
	\put(60,-60){\makebox(30,-150)[l]{\includegraphics[scale=0.5]{../images/boothist.pdf}}}
\end{picture}


\myNewSlide
\large
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/regions.pdf}}}
	\put(30,32){$R_0$}
	\put(80,32){$R_1$}
	\put(83,60){$\hat{\mu}$}
	\put(165,32){$R_0$}
	\put(215,32){$R_1$}
	\put(218,60){$\hat{\mu}$}
	\put(40,00){$\hat{\mu}$ is the best point calculated from the data}
\end{picture}

\myNewSlide

\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/regionsLFC.pdf}}}
	\put(30,32){$R_0$}
	\put(80,32){$R_1$}
	\put(83,60){$\hat{\mu}$}
	\put(63,60){${\mu_{\dag}}$}
	\put(165,32){$R_0$}
	\put(215,32){$R_1$}
	\put(218,60){$\hat{\mu}$}
	\put(198,60){${\mu_{\dag}}$}
	\put(40,00){$\hat{\mu}$ is the best point calculated from the data}
	\put(40,-10){${\mu_{\dag}}$ is least-favorable condition (LFC) point in $R_0$}
\end{picture}


\myNewSlide

\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/regionsTailRegions.pdf}}}
	\put(30,32){$R_0$}
	\put(80,32){$R_1$}
	\put(83,60){$\hat{\mu}$}
	\put(63,60){${\mu_{\dag}}$}
	\put(165,32){$R_0$}
	\put(215,32){$R_1$}
	\put(218,60){$\hat{\mu}$}
	\put(198,60){${\mu_{\dag}}$}
	\put(0,00){$\hat{\mu}$ is the best point calculated from the data}
	\put(0,-10){${\mu_{\dag}}$ is least-favorable condition (LFC) point in $R_0$}
	\put(0,-20){green areas are the tails - they correspond to values of the test}
	\put(5,-30){statistic more extreme than $\hat{\mu}$ (relative to that $\mu\in R_0$}
\end{picture}

\myNewSlide
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/regionsPValue.pdf}}}
	\put(30,32){$R_0$}
	\put(80,32){$R_1$}
	%\put(63,60){${\mu_{\dag}}$}
	\put(165,32){$R_0$}
	\put(215,32){$R_1$}
	%\put(198,60){${\mu_{\dag}}$}
	\put(40,00){$\hat{\mu}$ is the best point calculated from the data}
	\put(40,-10){${\mu_{\dag}}$ is least-favorable condition (LFC) point in $R_0$}
	\put(40,-20){Case 1 P-value $<$ the P-value in Case 2}
\end{picture}


\myNewSlide
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/regionsBootProp.pdf}}}
	\put(30,32){$R_0$}
	\put(80,32){$R_1$}
	%\put(63,60){${\mu_{\dag}}$}
	\put(165,32){$R_0$}
	\put(215,32){$R_1$}
	%\put(198,60){${\mu_{\dag}}$}
	%\put(40,00){$\hat{\mu}$ is the best point calculated from the data}
	%\put(40,-10){${\mu_{\dag}}$ is least-favorable condition (LFC) point in $R_0$}
	\put(-20,-20){In case 1 - the bootstrap proportion  is a good estimate of the P-value}
	\put(-20,-30){In case 2 - the bootstrap proportion underestimates the P-value}
\end{picture}

\myNewSlide
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/regions3.pdf}}}
	\put(30,32){$R_0$}
	\put(80,32){$R_1$}
	\put(63,60){${\mu_{\dag}}$}
	\put(43,60){$\hat{\mu}$}
	\put(165,32){$R_0$}
	\put(215,32){$R_1$}
	\put(198,60){${\mu_{\dag}}$}
	\put(178,60){$\hat{\mu}$}
	\put(40,00){$\hat{\mu}$ is the best point calculated from the data}
	\put(40,-10){${\mu_{\dag}}$ is least-favorable condition (LFC) point in $R_1$}
\end{picture}

\myNewSlide
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/regions3TailRegions.pdf}}}
	\put(30,32){$R_0$}
	\put(80,32){$R_1$}
	\put(63,60){${\mu_{\dag}}$}
	\put(43,60){$\hat{\mu}$}
	\put(165,32){$R_0$}
	\put(215,32){$R_1$}
	\put(198,60){${\mu_{\dag}}$}
	\put(178,60){$\hat{\mu}$}
	\put(0,00){$\hat{\mu}$ is the best point calculated from the data}
	\put(0,-10){${\mu_{\dag}}$ is least-favorable condition (LFC) point in $R_0$}
	\put(0,-20){green areas are the tails - they correspond to values of the test}
	\put(5,-30){statistic more extreme than $\hat{\mu}$ (relative to that $\mu\in R_1$)}
\end{picture}

\myNewSlide
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/regions3PValue.pdf}}}
	\put(30,32){$R_0$}
	\put(80,32){$R_1$}
	%\put(63,60){${\mu_{\dag}}$}
	\put(165,32){$R_0$}
	\put(215,32){$R_1$}
	%\put(198,60){${\mu_{\dag}}$}
	\put(40,-20){Case 3 P-value $>$ the P-value in Case 4}
\end{picture}

\myNewSlide
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/regions3BootProp.pdf}}}
	\put(30,32){$R_0$}
	\put(80,32){$R_1$}
	%\put(63,60){${\mu_{\dag}}$}
	\put(165,32){$R_0$}
	\put(215,32){$R_1$}
	%\put(198,60){${\mu_{\dag}}$}
	%\put(40,00){$\hat{\mu}$ is the best point calculated from the data}
	%\put(40,-10){${\mu_{\dag}}$ is least-favorable condition (LFC) point in $R_0$}
	\put(-20,-20){In case 3 - the bootstrap proportion  is a good estimate of the P-value}
	\put(-20,-30){In case 4 - the bootstrap proportion overestimates the P-value}
\end{picture}

\myNewSlide
\citet{EfronHH1996} pointed out these issues of curvature of the boundaries between tree hypotheses. 

We cannot see the boundaries in tree space, so it is hard to know how to correct for the biases so that we can use bootstrapping procedures as a means of getting a P-value for a clade  -- the probability that we would see this much support (or stronger support) for a clade if it were {\em not} present in the true tree.

\myNewSlide
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/efronBootCorrection.pdf}}}
	\put(53,60){$\hat{\mu}$}
	\put(178,60){$\hat{\mu}$}
\end{picture}

\myNewSlide
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/efronBootCorrection2.pdf}}}
	\put(53,60){$\hat{\mu}$}
	\put(178,60){$\hat{\mu}$}
\end{picture}

\myNewSlide
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/efronBootCorrection3.pdf}}}
\end{picture}

\myNewSlide
The corrected bootstrap procedure of \citet{EfronHH1996} requires a very large number of bootstrap replicates because you need very accurate estimates of the curvature in order to apply the correction. \citet{Shimodaira2002} expanded on this work:
\begin{compactitem}
	\item $d$ is the distance from the point that corresponds to the data and the closest point on the boundary between another tree
	\item $\Phi(\cdot)$ denotes the cumulative density function of the standard Normal(0,1) distribution.
	\item $c$ denotes the curvature of the boundary
	\item the P-value for the KH test is given by $KH=\Phi(d)$
\end{compactitem}

\myNewSlide
\begin{compactitem}
	\item Shimodaira argues (from an early Efron paper) that the appropriate P-value for tree selection is: \[AU = 1-\Phi(d-c)\]
	\item In ``standard'' non parametric bootstrapping proportions are: \[BP = 1 - \Phi(d+c)\] Note the incorrect sign with respect to the curvature term causes BP (and recall how on the curved boundary examples, the curvature caused the P-value to change in one direction and the BP to go in the other).
\end{compactitem}
How can we find $c$ so that we can correct for it?

\myNewSlide
\begin{compactitem}
	\item $N$ is the number of characters in the real data set
	\item $N^{\prime}$ is the number of characters in each bootstrap data set
	\item $r=\frac{N^{\prime}}{N}$
	\item If you do a bootstrap in which $r \neq 1 $, Shimodaira determined the expected effect on the bootstrap proportion as a function of $d$ and $c$:
	\[BP(r) = 1 - \Phi\left(d\sqrt{r} + \frac{c}{\sqrt{r}}\right)\]
\end{compactitem}

\myNewSlide
\begin{picture}(0,0)(0,100)
	\put(-10,-60){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../images/auMultiscale.pdf}}}
\end{picture}

\myNewSlide
\section*{AU Test}
		\begin{compactenum}
			\item conduct a sweep of bootstraps with $r$ varying (for instance $r = 0.5,  r=0.6, r=0.7, \ldots r=1.4$, to get a set of $BP(r)$ for a tree. 
			\item Use weighted least squares to estimate $c$ and $d$ form the set of $BP(r)$
			\item Calculate \[AU = 1-\Phi(d-c)\]
		\end{compactenum}
This lets you calculate a P-value for any tree of interest, and then you can construct a confidence set of trees.


\myNewSlide
\bibliography{phylo}
\end{document}     




\myNewSlide
\section*{Kishino Hasegawa Test (bootstrapping - continued)}
Bootstrapping can give us a sense of the variability, but if the original data favored tree 1 isn't it very likely that the bootstrapped replicates will be more likely to support tree 1 than tree 2?

This does not sound like we are following our null that both trees are equally good.

Solution: we must center the bootstrapped differences in score.
\myNewSlide
\includepdf[pages={2}]{images/polTopoTests.pdf} 

\myNewSlide
\includepdf[pages={4-5}]{images/polTopoTests.pdf} 

\myNewSlide
\includepdf[pages={10}]{images/polTopoTests.pdf} 

\myNewSlide
\section*{SH Test}
\normalsize
\begin{compactenum}
	\item Calculate the difference in lnL between each tree and the ML tree. Call this $\delta_{i}$
	\item Score each tree in your set on each bootstrap pseudoreplicate data set (using full optimization or RELL)
	\item Center the set of scores for each tree - force each tree's the mean lnL to be 0.0 by subtraction.
	\item For each bootstrap replicate calculate the difference between the best centered lnL and each tree's lnL - this is the $\delta_{i,j}$ for tree $i$ and bootstrap replicate $j$.
	\item For each tree count the proportion of bootstrap replicates in which $\delta_{ij}$ is larger (more extreme) than $\delta_{i}$.  This is the P-value for the tree.
	\item Reject trees that have P-values below the significance level for your test.
\end{compactenum}






\myNewSlide




